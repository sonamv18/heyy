{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGRAM 1 (A*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 3), (5, 4), (6, 5), (7, 6)]\n"
     ]
    }
   ],
   "source": [
    "class Node():     \n",
    "    \"\"\"A node class for A* Pathfinding\"\"\"  \n",
    "    def __init__(self, parent=None, position=None):         \n",
    "        self.parent = parent         \n",
    "        self.position = position  \n",
    "        self.g = 0         \n",
    "        self.h = 0         \n",
    "        self.f = 0  \n",
    "    def __eq__(self, other):         \n",
    "        return self.position == other.position  \n",
    "    \n",
    "def astar(maze, start, end):     \n",
    "    \"\"\"Returns a list of tuples as a path from the given start to the given end in the given maze\"\"\"  \n",
    "    # Create start and end node     \n",
    "    start_node = Node(None, start)     \n",
    "    start_node.g = start_node.h = start_node.f = 0     \n",
    "    end_node = Node(None, end)     \n",
    "    end_node.g = end_node.h = end_node.f = 0  \n",
    "    # Initialize both open and closed list     \n",
    "    open_list = []     \n",
    "    closed_list = []  \n",
    "    # Add the start node     \n",
    "    open_list.append(start_node)  \n",
    "    # Loop until you find the end     \n",
    "    while len(open_list) > 0:  \n",
    "        # Get the current node         \n",
    "        current_node = open_list[0]         \n",
    "        current_index = 0         \n",
    "        for index, item in enumerate(open_list):             \n",
    "            if item.f < current_node.f:                 \n",
    "                current_node = item                 \n",
    "                current_index = index  \n",
    "        # Pop current off open list, add to closed list         \n",
    "        open_list.pop(current_index)         \n",
    "        closed_list.append(current_node)  \n",
    "        # Found the goal         \n",
    "        if current_node == end_node:             \n",
    "            path = []             \n",
    "            current = current_node             \n",
    "            while current is not None:                 \n",
    "                path.append(current.position)                 \n",
    "                current = current.parent \n",
    "            return path[::-1] # Return reversed path\n",
    "        # Generate children         \n",
    "        children = []         \n",
    "        for new_position in [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]: # Adjacent squares  \n",
    "            # Get node position             \n",
    "            node_position = (current_node.position[0] + new_position[0], current_node.position[1] + new_position[1])  \n",
    "            # Make sure within range             \n",
    "            if node_position[0] > (len(maze) - 1) or node_position[0] < 0 or node_position[1] > (len(maze[len(maze)-1]) -1) or node_position[1] < 0:                 \n",
    "                continue  \n",
    "            # Make sure walkable terrain             \n",
    "            if maze[node_position[0]][node_position[1]] != 0:                 \n",
    "                continue  \n",
    "            # Create new node             \n",
    "            new_node = Node(current_node, node_position)  \n",
    "            # Append             \n",
    "            children.append(new_node)  \n",
    "        # Loop through children         \n",
    "        for child in children:  \n",
    "            # Child is on the closed list             \n",
    "            for closed_child in closed_list:                 \n",
    "                if child == closed_child:                     \n",
    "                    continue  \n",
    "            # Create the f, g, and h values             \n",
    "            child.g = current_node.g + 1             \n",
    "            child.h = ((child.position[0] - end_node.position[0]) ** 2) + ((child.position[1] - end_node.position[1]) ** 2)             \n",
    "            child.f = child.g + child.h  \n",
    "            # Child is already in the open list             \n",
    "            for open_node in open_list:                 \n",
    "                if child == open_node and child.g > open_node.g:                     \n",
    "                    continue  \n",
    "            # Add the child to the open list             \n",
    "            open_list.append(child) \n",
    "            \n",
    "\n",
    "def main():  \n",
    "    maze = [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]  \n",
    "    start = (0, 0)     \n",
    "    end = (7, 6)  \n",
    "    path = astar(maze, start, end)     \n",
    "    print(path)   \n",
    "if __name__ == '__main__':     \n",
    "    main()   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate elimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Given Training Data Set \n",
      "\n",
      "['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'Yes']\n",
      "['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'Yes']\n",
      "['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'No']\n",
      "['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'Yes']\n",
      "\n",
      " The initial value of hypothesis: \n",
      "\n",
      " The most specific hypothesis S0 : [0,0,0,0,0,0]\n",
      "\n",
      " \n",
      " The most general hypothesis G0 : [?,?,?,?,?,?]\n",
      "\n",
      "\n",
      " Candidate Elimination algorithm  Hypotheses Version Space Computation\n",
      "\n",
      " For Training Example No :1 the hypothesis is S1   ['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same']\n",
      " For Training Example No :1 the hypothesis is G1  ['?', '?', '?', '?', '?', '?']\n",
      " For Training Example No :2 the hypothesis is S2   ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      " For Training Example No :2 the hypothesis is G2  ['?', '?', '?', '?', '?', '?']\n",
      " For Training Example No :3 the hypothesis is S3  ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      " For Training Example No :3 the hypothesis is G3 [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]\n",
      " For Training Example No :4 the hypothesis is S4   ['Sunny', 'Warm', '?', 'Strong', '?', '?']\n",
      " For Training Example No :4 the hypothesis is G4 [['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "a = []\n",
    "print(\"\\n The Given Training Data Set \\n\")\n",
    "\n",
    "with open('ws.csv', 'r') as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    for row in reader:\n",
    "        a.append (row)\n",
    "        print(row)\n",
    "num_attributes = len(a[0])-1 # we don't want last col which is target concet ( yes/no)\n",
    "\n",
    "print(\"\\n The initial value of hypothesis: \")\n",
    "S = ['0'] * num_attributes\n",
    "G = ['?'] * num_attributes\n",
    "print (\"\\n The most specific hypothesis S0 : [0,0,0,0,0,0]\\n\")\n",
    "print (\" \\n The most general hypothesis G0 : [?,?,?,?,?,?]\\n\")\n",
    "\n",
    "for j in range(0,num_attributes):\n",
    "       S[j] = a[0][j];\n",
    "\n",
    "# Comparing with Remaining Training Examples of Given Data Set\n",
    "\n",
    "print(\"\\n Candidate Elimination algorithm  Hypotheses Version Space Computation\\n\")\n",
    "temp=[]\n",
    "\n",
    "for i in range(0,len(a)):\n",
    "    if a[i][num_attributes]=='Yes':\n",
    "        for j in range(0,num_attributes):\n",
    "            if a[i][j]!=S[j]:\n",
    "                S[j]='?'\n",
    "\n",
    "        for j in range(0,num_attributes):\n",
    "            for k  in range(0,len(temp)):\n",
    "                if temp[k][j] != '?' and temp[k][j] != S[j]:\n",
    "                    del temp[k] #remove it if it's not matching with the specific hypothesis\n",
    "\n",
    "        print(\" For Training Example No :{0} the hypothesis is S{0}  \".format(i+1),S)\n",
    "\n",
    "        if (len(temp)==0):\n",
    "            print(\" For Training Example No :{0} the hypothesis is G{0} \".format(i+1),G)\n",
    "        else:\n",
    "            print(\" For Training Example No :{0} the hypothesis is G{0}\".format(i+1),temp)\n",
    "\n",
    "    if a[i][num_attributes]=='No': \n",
    "        for j in range(0,num_attributes):\n",
    "             if S[j] != a[i][j] and S[j]!= '?':  #if not  matching with the specific Hypothesis take it seperately and store it \n",
    "                 G[j]=S[j]\n",
    "                 temp.append(G) # this is the version space to store all Hypotheses\n",
    "                 G = ['?'] * num_attributes\n",
    "\n",
    "        print(\" For Training Example No :{0} the hypothesis is S{0} \".format(i+1),S)\n",
    "        print(\" For Training Example No :{0} the hypothesis is G{0}\".format(i+1),temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree id3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " outlook\n",
      "    o\u0000\u0000\u0000v\u0000\u0000\u0000e\u0000\u0000\u0000r\u0000\u0000\u0000c\u0000\u0000\u0000a\u0000\u0000\u0000s\u0000\u0000\u0000t\u0000\u0000\u0000\n",
      "       yes\n",
      "    r\u0000\u0000\u0000a\u0000\u0000\u0000i\u0000\u0000\u0000n\u0000\u0000\u0000y\u0000\u0000\u0000\n",
      "       windy\n",
      "          Strong\n",
      "             no\n",
      "          Weak\n",
      "             yes\n",
      "    s\u0000\u0000\u0000u\u0000\u0000\u0000n\u0000\u0000\u0000n\u0000\u0000\u0000y\u0000\u0000\u0000\n",
      "       humidity\n",
      "          high\n",
      "             no\n",
      "          normal\n",
      "             yes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = []\n",
    "        self.answer = \"\"\n",
    "        \n",
    "def read_data(filename):\n",
    "    \"\"\" read csv file and return header and data  \"\"\"\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile, delimiter=',')\n",
    "        metadata = next(datareader)\n",
    "        traindata=[]\n",
    "        for row in datareader:\n",
    "            traindata.append(row)\n",
    "            \n",
    "    return (metadata, traindata)\n",
    "\n",
    "\n",
    "\n",
    "def subtables(data, col, delete):\n",
    "    dict = {}\n",
    "    items = np.unique(data[:, col]) # get unique values in a particular column\n",
    "    \n",
    "    count = np.zeros((items.shape[0], 1), dtype=np.int32)   #number of row = number of values \n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "        for y in range(data.shape[0]):\n",
    "            if data[y, col] == items[x]:\n",
    "                count[x] += 1\n",
    "    #count has the data of number of times each value is present in\n",
    "                \n",
    "    for x in range(items.shape[0]):\n",
    "        dict[items[x]] = np.empty((int(count[x]), data.shape[1]), dtype=\"|S32\")\n",
    "         \n",
    "        pos = 0\n",
    "        for y in range(data.shape[0]):\n",
    "            if data[y, col] == items[x]:\n",
    "                dict[items[x]][pos] = data[y]\n",
    "                pos += 1     \n",
    "        \n",
    "        if delete:\n",
    "           dict[items[x]] = np.delete(dict[items[x]], col, 1)\n",
    "    return items, dict    \n",
    "        \n",
    "        \n",
    "        \n",
    "def entropy(S):\n",
    "    \"\"\" calculate the entropy \"\"\"\n",
    "    items = np.unique(S)\n",
    "    if items.size == 1:\n",
    "        return 0\n",
    "    \n",
    "    counts = np.zeros((items.shape[0], 1))\n",
    "    sums = 0\n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "        counts[x] = sum(S == items[x]) / (S.size)\n",
    "        \n",
    "    for count in counts:\n",
    "        sums += -1 * count * math.log(count, 2)\n",
    "    return sums\n",
    "    \n",
    "def gain_ratio(data, col):\n",
    "    items, dict = subtables(data, col, delete=False) \n",
    "    #item is the unique value and dict is the data corresponding to it\n",
    "    total_size = data.shape[0]\n",
    "    entropies = np.zeros((items.shape[0], 1))\n",
    "      \n",
    "    for x in range(items.shape[0]):\n",
    "        ratio = dict[items[x]].shape[0]/(total_size)\n",
    "        entropies[x] = ratio * entropy(dict[items[x]][:, -1])\n",
    "        \n",
    "        \n",
    "    total_entropy = entropy(data[:, -1])\n",
    "   \n",
    "    \n",
    "    for x in range(entropies.shape[0]):\n",
    "        total_entropy -= entropies[x]\n",
    "        \n",
    "    return total_entropy\n",
    "\n",
    "\n",
    "def create_node(data, metadata):\n",
    "\n",
    "    if (np.unique(data[:, -1])).shape[0] == 1: #to check how many rows in last col(yes,no column). shape[0] gives no. of rows \n",
    "        ''' if there is only yes or only no then reutrn a node containing the value '''\n",
    "        node = Node(\"\")\n",
    "        node.answer = np.unique(data[:, -1])\n",
    "        return node\n",
    "     \n",
    "    gains = np.zeros((data.shape[1] - 1, 1))  # data.shape[1] - 1 returns the no of columns in the dataset, minus one to remove last column\n",
    "    #size of gains= number of attribute to calculate gain\n",
    "    #gains is one dim array (size=4) to store the gain of each attribute \n",
    "    \n",
    "    for col in range(data.shape[1] - 1):\n",
    "        gains[col] = gain_ratio(data, col)\n",
    "        \n",
    "    split = np.argmax(gains) # argmax returns the index of the max value\n",
    "  \n",
    "    \n",
    "    node = Node(metadata[split])    \n",
    "    metadata = np.delete(metadata, split, 0)\n",
    "                          \n",
    "    \n",
    "    items, dict = subtables(data, split, delete=True)\n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "        child = create_node(dict[items[x]], metadata)\n",
    "        node.children.append((items[x], child))\n",
    "    \n",
    "    return node        \n",
    "    \n",
    "def empty(size):\n",
    "    \"\"\" To generate empty space needed for shaping the tree\"\"\"\n",
    "    s = \"\"\n",
    "    for x in range(size):\n",
    "        s += \"   \"\n",
    "    return s\n",
    "\n",
    "def print_tree(node, level):\n",
    "    if node.answer != \"\":\n",
    "\n",
    "        print(empty(level), node.answer.item(0).decode(\"utf-8\"))\n",
    "        return\n",
    "        \n",
    "    print(empty(level), node.attribute)\n",
    "    \n",
    "    for value, n in node.children:\n",
    "        print(empty(level + 1), value.tobytes().decode(\"utf-8\"))\n",
    "        print_tree(n, level + 2)\n",
    "        \n",
    "\n",
    "metadata, traindata = read_data(\"tennis.csv\")\n",
    "data = np.array(traindata) # to convert the traindata to numpy array \n",
    "node = create_node(data, metadata)\n",
    "print_tree(node, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01519819]\n",
      " [0.95510313]\n",
      " [0.91549755]] W\n",
      "[[0.01519819 0.95510313 0.91549755]] WT\n",
      "[[0.9406462 ]\n",
      " [0.93398837]\n",
      " [0.94082293]] output\n",
      "Input: \n",
      "[[2 9]\n",
      " [1 5]\n",
      " [3 6]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9406462 ]\n",
      " [0.93398837]\n",
      " [0.94082293]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(([2, 9], [1, 5], [3, 6])) # Hours Studied, Hours Slept \n",
    "y = np.array(([92], [86], [89])) # Test Score\n",
    "\n",
    "y = y/100 # max test score is 100\n",
    "\n",
    "\n",
    "#Sigmoid Function\n",
    "def sigmoid(x): #this function maps any value between 0 and 1\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Derivative of Sigmoid Function\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#Variable initialization\n",
    "epoch=1 #Setting training iterations\n",
    "lr=0.1 #Setting learning rate\n",
    "inputlayer_neurons = 2 #number of features in data set\n",
    "hiddenlayer_neurons = 3 #number of hidden layers neurons\n",
    "output_neurons = 1 #number of neurons of output layer\n",
    "\n",
    "#weight and bias initialization\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "bias_hidden=np.random.uniform(size=(1,hiddenlayer_neurons)) #bias matrix to the hidden layer\n",
    "weight_hidden=np.random.uniform(size=(hiddenlayer_neurons,output_neurons)) #weight matrix to the output layer\n",
    "bias_output=np.random.uniform(size=(1,output_neurons)) # matrix to the output layer\n",
    "print(weight_hidden,\"W\")\n",
    "print(weight_hidden.T,\"WT\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    #Forward Propogation\n",
    "    hinp1=np.dot(X,wh)\n",
    "    hinp= hinp1 + bias_hidden #bias_hidden GRADIENT DISCENT\n",
    "    hlayer_activation = sigmoid(hinp)\n",
    "    \n",
    "    outinp1=np.dot(hlayer_activation,weight_hidden)\n",
    "    outinp= outinp1+ bias_output\n",
    "    output = sigmoid(outinp)\n",
    "    print(output,\"output\")\n",
    "    #Backpropagation\n",
    "    EO = y-output #Compare prediction with actual output and calculate the gradient of error (Actual – Predicted)\n",
    "\n",
    "    outgrad = derivatives_sigmoid(output) #Compute the slope/ gradient of hidden and output layer neurons\n",
    "\n",
    "    d_output = EO * outgrad #Compute change factor(delta) at output layer, dependent on the gradient of error multiplied by the slope of output layer activation\n",
    "#     print(weight_hidden,weight_hidden.T,\"T\")\n",
    "    EH = d_output.dot(weight_hidden.T)  #At this step, the error will propagate back into the network which means error at hidden layer. we will take the dot product of output layer delta with weight parameters of edges between the hidden and output layer (weight_hidden.T).\n",
    "    \n",
    "    hiddengrad = derivatives_sigmoid(hlayer_activation) #how much hidden layer weight contributed to error\n",
    "    d_hiddenlayer = EH * hiddengrad\n",
    "\n",
    "\n",
    "    #update the weights\n",
    "    weight_hidden += hlayer_activation.T.dot(d_output) *lr# dot product of nextlayererror and currentlayerop\n",
    "    bias_hidden += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr\n",
    "\n",
    "    wh += X.T.dot(d_hiddenlayer) *lr\n",
    "    bias_output += np.sum(d_output, axis=0,keepdims=True) *lr\n",
    "\n",
    "print(\"Input: \\n\" + str(X))\n",
    "print(\"Actual Output: \\n\" + str(y))\n",
    "print(\"Predicted Output: \\n\" ,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navie Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sunny', 'hot', 'high', 'Weak', 'no'], ['sunny', 'hot', 'high', 'Strong', 'no'], ['overcast', 'hot', 'high', 'Weak', 'yes'], ['rainy', 'mild', 'high', 'Weak', 'yes'], ['rainy', 'cool', 'normal', 'Weak', 'yes'], ['rainy', 'cool', 'normal', 'Strong', 'no'], ['overcast', 'cool', 'normal', 'Strong', 'yes'], ['sunny', 'mild', 'high', 'Weak', 'no']]\n",
      "training data size= 8\n",
      "test data size= 6\n",
      "target    count    probability\n",
      "Yes \t 4 \t 0.5\n",
      "No \t 4 \t 0.5\n",
      "instance prediction  target\n",
      "1 \t no \t     yes\n",
      "2 \t yes \t     yes\n",
      "3 \t no \t     yes\n",
      "4 \t yes \t     yes\n",
      "5 \t yes \t     yes\n",
      "6 \t no \t     no\n",
      "accuracy 66.66666666666666 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import pdb\n",
    "def read_data(filename):\n",
    "    with open(filename,'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile)\n",
    "        metadata = next(datareader)\n",
    "        traindata=[]\n",
    "        for row in datareader:\n",
    "            traindata.append(row)\n",
    "\n",
    "    return (metadata, traindata)\n",
    "\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    testset = list(dataset)\n",
    "    i=0\n",
    "    while len(trainSet) < trainSize:\n",
    "        trainSet.append(testset.pop(i))\n",
    "    print(trainSet)\n",
    "    return [trainSet, testset]\n",
    "\n",
    "def classify(data,test):\n",
    "\n",
    "    total_size = data.shape[0]\n",
    "    print(\"training data size=\",total_size)\n",
    "    print(\"test data size=\",test.shape[0])\n",
    "\n",
    "    countYes = 0\n",
    "    countNo = 0\n",
    "    probYes = 0\n",
    "    probNo = 0\n",
    "    print(\"target    count    probability\")\n",
    "\n",
    "    for x in range(data.shape[0]):\n",
    "        if data[x,data.shape[1]-1] == 'yes':\n",
    "            countYes +=1\n",
    "        if data[x,data.shape[1]-1] == 'no':\n",
    "            countNo +=1\n",
    "\n",
    "    probYes=countYes/total_size\n",
    "    probNo= countNo / total_size\n",
    "\n",
    "    print('Yes',\"\\t\",countYes,\"\\t\",probYes)\n",
    "    print('No',\"\\t\",countNo,\"\\t\",probNo)\n",
    "\n",
    "\n",
    "    prob0 =np.zeros((test.shape[1]-1))\n",
    "    prob1 =np.zeros((test.shape[1]-1))\n",
    "    accuracy=0\n",
    "    print(\"instance prediction  target\")\n",
    "\n",
    "    for t in range(test.shape[0]):\n",
    "        for k in range (test.shape[1]-1):\n",
    "            count1=count0=0\n",
    "            for j in range (data.shape[0]):\n",
    "                #how many times appeared with no\n",
    "                if test[t,k] == data[j,k] and data[j,data.shape[1]-1]=='no':\n",
    "                    count0+=1\n",
    "                #how many times appeared with yes\n",
    "                if test[t,k]==data[j,k] and data[j,data.shape[1]-1]=='yes':\n",
    "                    count1+=1\n",
    "            prob0[k]=count0/countNo\n",
    "            prob1[k]=count1/countYes\n",
    "\n",
    "        probno=probNo\n",
    "        probyes=probYes\n",
    "        for i in range(test.shape[1]-1):\n",
    "            probno=probno*prob0[i]\n",
    "            probyes=probyes*prob1[i]\n",
    "        if probno>probyes:\n",
    "            predict='no'\n",
    "        else:\n",
    "            predict='yes'\n",
    "\n",
    "        print(t+1,\"\\t\",predict,\"\\t    \",test[t,test.shape[1]-1])\n",
    "        if predict == test[t,test.shape[1]-1]:\n",
    "            accuracy+=1\n",
    "    final_accuracy=(accuracy/test.shape[0])*100\n",
    "    print(\"accuracy\",final_accuracy,\"%\")\n",
    "    return\n",
    "\n",
    "metadata,traindata= read_data(\"tennis1.csv\")\n",
    "splitRatio=0.6                                                     #split into training and testing\n",
    "trainingset, testset=splitDataset(traindata, splitRatio)\n",
    "training=np.array(trainingset)\n",
    "testing=np.array(testset)\n",
    "\n",
    "classify(training,testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AO STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph - 2\n",
      "HEURISTIC VALUES : {'A': 1, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {}\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "11 ['D']\n",
      "HEURISTIC VALUES : {'A': 11, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {}\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "10 ['E', 'F']\n",
      "HEURISTIC VALUES : {'A': 11, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {}\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "11 ['D']\n",
      "HEURISTIC VALUES : {'A': 11, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {}\n",
      "PROCESSING NODE : E\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "HEURISTIC VALUES : {'A': 11, 'B': 6, 'C': 12, 'D': 10, 'E': 0, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {'E': []}\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "6 ['E', 'F']\n",
      "HEURISTIC VALUES : {'A': 11, 'B': 6, 'C': 12, 'D': 6, 'E': 0, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {'E': []}\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "7 ['D']\n",
      "HEURISTIC VALUES : {'A': 7, 'B': 6, 'C': 12, 'D': 6, 'E': 0, 'F': 4, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {'E': []}\n",
      "PROCESSING NODE : F\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "HEURISTIC VALUES : {'A': 7, 'B': 6, 'C': 12, 'D': 6, 'E': 0, 'F': 0, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {'E': [], 'F': []}\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "HEURISTIC VALUES : {'A': 7, 'B': 6, 'C': 12, 'D': 2, 'E': 0, 'F': 0, 'G': 5, 'H': 7}\n",
      "SOLUTION GRAPH : {'E': [], 'F': [], 'D': ['E', 'F']}\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "FOR GRAPH SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE: A\n",
      "------------------------------------------------------------\n",
      "{'E': [], 'F': [], 'D': ['E', 'F'], 'A': ['D']}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Graph:\n",
    "    def __init__(self, graph, heuristicNodeList, startNode): #instantiate graph object with graph topology, heuristic values, start node\n",
    "        self.graph = graph\n",
    "        self.H=heuristicNodeList\n",
    "        self.start=startNode\n",
    "        self.parent={}\n",
    "        self.status={}\n",
    "        self.solutionGraph={}\n",
    "        \n",
    "    def applyAOStar(self): # starts a recursive AO* algorithm\n",
    "        self.aoStar(self.start, False)\n",
    "\n",
    "    def getNeighbors(self, v): # gets the Neighbors of a given node\n",
    "        return self.graph.get(v,'')\n",
    "\n",
    "    def getStatus(self,v): # return the status of a given node\n",
    "        return self.status.get(v,0)\n",
    "\n",
    "    def setStatus(self,v, val): # set the status of a given node\n",
    "        self.status[v]=val\n",
    "\n",
    "    def getHeuristicNodeValue(self, n):\n",
    "        return self.H.get(n,0) # always return the heuristic value of a given node\n",
    "\n",
    "    def setHeuristicNodeValue(self, n, value):\n",
    "        self.H[n]=value # set the revised heuristic value of a given node\n",
    "\n",
    "    def printSolution(self):\n",
    "        print(\"FOR GRAPH SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE:\",self.start)\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print(self.solutionGraph)\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "    def computeMinimumCostChildNodes(self, v): # Computes the Minimum Cost of child nodes of a given node v\n",
    "        minimumCost=0\n",
    "        costToChildNodeListDict={}\n",
    "        costToChildNodeListDict[minimumCost]=[]\n",
    "        flag=True\n",
    "        for nodeInfoTupleList in self.getNeighbors(v): # iterate over all the set of child node/s\n",
    "            cost=0\n",
    "            nodeList=[]\n",
    "            for c, weight in nodeInfoTupleList:\n",
    "                cost=cost+self.getHeuristicNodeValue(c)+weight\n",
    "                nodeList.append(c)\n",
    "            if flag==True: # initialize Minimum Cost with the cost of first set of child node/s\n",
    "                minimumCost=cost\n",
    "                costToChildNodeListDict[minimumCost]=nodeList # set the Minimum Cost child node/s\n",
    "                flag=False\n",
    "            else: # checking the Minimum Cost nodes with the current Minimum Cost\n",
    "                if minimumCost>cost:\n",
    "                    minimumCost=cost\n",
    "                    costToChildNodeListDict[minimumCost]=nodeList # set the Minimum Cost child node/s\n",
    "        return minimumCost, costToChildNodeListDict[minimumCost] # return Minimum Cost and Minimum Cost child node/s\n",
    "\n",
    "    def aoStar(self, v, backTracking): # AO* algorithm for a start node and backTracking status flag\n",
    "        print(\"HEURISTIC VALUES :\", self.H)\n",
    "        print(\"SOLUTION GRAPH :\", self.solutionGraph)\n",
    "        print(\"PROCESSING NODE :\", v)\n",
    "        print(\"-----------------------------------------------------------------------------------------\")\n",
    "        if self.getStatus(v) >= 0: # if status node v >= 0, compute Minimum Cost nodes of v\n",
    "            minimumCost, childNodeList = self.computeMinimumCostChildNodes(v)\n",
    "            print(minimumCost, childNodeList)\n",
    "            self.setHeuristicNodeValue(v, minimumCost)\n",
    "            self.setStatus(v,len(childNodeList))\n",
    "            solved=True # check the Minimum Cost nodes of v are solved\n",
    "            for childNode in childNodeList:\n",
    "                self.parent[childNode]=v\n",
    "                if self.getStatus(childNode)!=-1:\n",
    "                    solved=solved & False\n",
    "            if solved==True: # if the Minimum Cost nodes of v are solved, set the current node status as solved(-1)\n",
    "                self.setStatus(v,-1)\n",
    "                self.solutionGraph[v]=childNodeList # update the solution graph with the solved nodes which may be a part of solution\n",
    "            if v!=self.start: # check the current node is the start node for backtracking the current node value\n",
    "                self.aoStar(self.parent[v], True) # backtracking the current node value with backtracking status set to true\n",
    "            if backTracking==False: # check the current call is not for backtracking \n",
    "                for childNode in childNodeList: # for each Minimum Cost child node\n",
    "                    self.setStatus(childNode,0) # set the status of child node to 0(needs exploration)\n",
    "                    self.aoStar(childNode, False) # Minimum Cost child node is further explored with backtracking status as false\n",
    "# print (\"Graph - 1\")\n",
    "# h1 = {'A': 1, 'B': 6, 'C': 2, 'D': 12, 'E': 2, 'F': 1, 'G': 5, 'H': 7, 'I': 7, 'J': 1}\n",
    "# graph1 = {\n",
    "#     'A': [[('B', 1), ('C', 1)], [('D', 1)]],\n",
    "#     'B': [[('G', 1)], [('H', 1)]],\n",
    "#     'C': [[('J', 1)]],\n",
    "#     'D': [[('E', 1), ('F', 1)]],\n",
    "#     'G': [[('I', 1)]]\n",
    "# }\n",
    "\n",
    "# G1= Graph(graph1, h1, 'A')\n",
    "# G1.applyAOStar()\n",
    "# G1.printSolution()\n",
    "\n",
    "\n",
    "print (\"Graph - 2\")\n",
    "h2 = {'A': 1, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7} # Heuristic values of Nodes\n",
    "graph2 = { # Graph of Nodes and Edges\n",
    "    'A': [[('B', 1), ('C', 1)], [('D', 1)]], # Neighbors of Node 'A', B, C & D with repective weights\n",
    "    'B': [[('G', 1)], [('H', 1)]], # Neighbors are included in a list of lists\n",
    "    'D': [[('E', 1), ('F', 1)]] # Each sublist indicate a \"OR\" node or \"AND\" nodes\n",
    "}\n",
    "\n",
    "G2 = Graph(graph2, h2, 'A') # Instantiate Graph object with graph, heuristic values and start Node\n",
    "G2.applyAOStar() # Run the AO* algorithm\n",
    "G2.printSolution() # Print the solution graph as output of the AO* algorithm search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is as follows\n",
      "[[19  0  0]\n",
      " [ 0 13  1]\n",
      " [ 0  0 12]]\n",
      "Accuracy Matrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       1.00      0.93      0.96        14\n",
      "          2       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "The final accuracy score is  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "iris_data=iris.data\n",
    "iris_labels=iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(iris_data,iris_labels,test_size=0.30)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5) \n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred=classifier.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "print('Confusion matrix is as follows')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy Matrics')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"The final accuracy score is \", metrics.accuracy_score(y_test,classifier.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
